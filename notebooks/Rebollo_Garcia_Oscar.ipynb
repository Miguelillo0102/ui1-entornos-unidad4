{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejemplo de transformaci√≥n, limpieza y procesado de conjuntos de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "games_df = spark.read.csv('../data/games.csv', header=True, sep=',', inferSchema=True)\n",
    "games_red_df = games_df.selectExpr('winner',\n",
    "                                   'gameDuration as duration',\n",
    "                                   'firstBlood',\n",
    "                                   'firstTower',\n",
    "                                   'firstInhibitor',\n",
    "                                   'firstBaron',\n",
    "                                   'firstDragon',\n",
    "                                   'firstRiftHerald',\n",
    "                                   't1_champ1id',\n",
    "                                   't1_champ2id',\n",
    "                                   't1_champ3id',\n",
    "                                   't1_champ4id',\n",
    "                                   't1_champ5id',\n",
    "                                   't1_towerKills',\n",
    "                                   't1_inhibitorKills',\n",
    "                                   't1_baronKills',\n",
    "                                   't1_dragonKills',\n",
    "                                   't1_riftHeraldKills',\n",
    "                                   't2_champ1id',\n",
    "                                   't2_champ2id',\n",
    "                                   't2_champ3id',\n",
    "                                   't2_champ4id',\n",
    "                                   't2_champ5id',\n",
    "                                   't2_towerKills',\n",
    "                                   't2_inhibitorKills',\n",
    "                                   't2_baronKills',\n",
    "                                   't2_dragonKills',\n",
    "                                   't2_riftHeraldKills')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import expr\n",
    "from pyspark.ml.feature import CountVectorizer\n",
    "new_column_expression = expr('split( concat_ws( \",\" ,t1_champ1id, t1_champ2id, t1_champ3id, t1_champ4id, t1_champ5id), \",\" )' )\n",
    "games_red_cv_df = games_red_df.withColumn('t1_members_str',new_column_expression).drop('t1_champ1id', 't1_champ2id', 't1_champ3id', 't1_champ4id', 't1_champ5id')\n",
    "cv = CountVectorizer(inputCol='t1_members_str', outputCol='t1_members')\n",
    "model = cv.fit(games_red_cv_df)\n",
    "games_red_cv_df=model.transform(games_red_cv_df).drop('t1_members_str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import expr\n",
    "new_column_expression = expr('split( concat_ws( \",\" ,t2_champ1id, t2_champ2id, t2_champ3id, t2_champ4id, t2_champ5id), \",\" )' )\n",
    "games_red_cv_df = games_red_cv_df.withColumn('t2_members_str',new_column_expression).drop('t2_champ1id', 't2_champ2id', 't2_champ3id', 't2_champ4id', 't2_champ5id')\n",
    "cv = CountVectorizer(inputCol='t2_members_str', outputCol='t2_members')\n",
    "model = cv.fit(games_red_cv_df)\n",
    "games_red_cv_df=model.transform(games_red_cv_df).drop('t2_members_str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Binarizer\n",
    "from pyspark.sql.types import DoubleType\n",
    "games_red_cv_df = games_red_cv_df.withColumn('winner', games_red_cv_df.winner.cast(DoubleType()))\n",
    "transformer=Binarizer(inputCol='winner', outputCol='winner_b', threshold=1)\n",
    "games_red_cv_df=transformer.transform(games_red_cv_df).drop('winner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoderEstimator\n",
    "columns = ['firstBlood', 'firstTower', 'firstInhibitor', 'firstBaron', 'firstDragon', 'firstRiftHerald']\n",
    "new_columns = [ 'b_firstBlood', 'b_firstTower', 'b_firstInhibitor', 'b_firstBaron', 'b_firstDragon', 'b_firstRiftHerald' ]\n",
    "model = OneHotEncoderEstimator(inputCols=columns, outputCols=new_columns,dropLast=False)\n",
    "transformer=model.fit(games_red_cv_df)\n",
    "games_red_cv_df=transformer.transform(games_red_cv_df)\n",
    "for column in columns :\n",
    "    games_red_cv_df = games_red_cv_df.drop(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StandardScaler, VectorAssembler\n",
    "columns = [\"duration\", \"t1_towerKills\", \"t1_inhibitorKills\", \"t1_baronKills\", \"t1_dragonKills\", \"t1_riftHeraldKills\",\n",
    "          \"t2_towerKills\", \"t2_inhibitorKills\", \"t2_baronKills\", \"t2_dragonKills\", \"t2_riftHeraldKills\"]\n",
    "assembler = VectorAssembler(inputCols=columns, outputCol=\"assembledColumns\")\n",
    "games_red_cv_df=assembler.transform(games_red_cv_df)\n",
    "model = StandardScaler(inputCol=\"assembledColumns\", outputCol=\"standardColumns\", withStd=True, withMean=True)\n",
    "transformer = model.fit(games_red_cv_df)\n",
    "games_red_cv_df=transformer.transform(games_red_cv_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['t1_members', 't2_members', 'b_firstBlood', 'b_firstBaron', 'b_firstDragon', 'b_firstInhibitor', 'b_firstRiftHerald', 'b_firstTower', 'standardColumns']\n",
    "assembler = VectorAssembler(inputCols=columns, outputCol='features')\n",
    "games_red_cv_df = assembler.transform(games_red_cv_df)\n",
    "dataset = games_red_cv_df.selectExpr('winner_b as label', 'features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import PCA\n",
    "model = PCA(inputCol='features', outputCol='red_features',k=50)\n",
    "transformer = model.fit(dataset)\n",
    "red_dataset=transformer.transform(dataset).drop('features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejemplo de entrenamiento con Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "[train_df, test_df]=games_red_df.randomSplit([0.7, 0.3])\n",
    "train_df = train_df.withColumn('winner', train_df.winner.cast(DoubleType()))\n",
    "test_df = test_df.withColumn('winner', test_df.winner.cast(DoubleType()))\n",
    "new_column_expression = expr('split( concat_ws( \",\" ,t1_champ1id, t1_champ2id, t1_champ3id, t1_champ4id, t1_champ5id), \",\" )' )\n",
    "train_df = train_df.withColumn('t1_members_str',new_column_expression)\n",
    "test_df = test_df.withColumn('t1_members_str', new_column_expression)\n",
    "new_column_expression = expr('split( concat_ws( \",\" ,t2_champ1id, t2_champ2id, t2_champ3id, t2_champ4id, t2_champ5id), \",\" )' )\n",
    "train_df = train_df.withColumn('t2_members_str',new_column_expression)\n",
    "test_df = test_df.withColumn('t2_members_str', new_column_expression)\n",
    "cv1 = CountVectorizer(inputCol='t1_members_str', outputCol='t1_members')\n",
    "cv2 = CountVectorizer(inputCol='t2_members_str', outputCol='t2_members')\n",
    "binarizer=Binarizer(inputCol='winner', outputCol='winner_b', threshold=1)\n",
    "columns = ['firstBlood', 'firstTower', 'firstInhibitor', 'firstBaron', 'firstDragon', 'firstRiftHerald']\n",
    "new_columns = [ 'b_firstBlood', 'b_firstTower', 'b_firstInhibitor', 'b_firstBaron', 'b_firstDragon', 'b_firstRiftHerald' ]\n",
    "ohe = OneHotEncoderEstimator(inputCols=columns, outputCols=new_columns,dropLast=False)\n",
    "columns = [\"duration\", \"t1_towerKills\", \"t1_inhibitorKills\", \"t1_baronKills\", \"t1_dragonKills\", \"t1_riftHeraldKills\",\n",
    "          \"t2_towerKills\", \"t2_inhibitorKills\", \"t2_baronKills\", \"t2_dragonKills\", \"t2_riftHeraldKills\"]\n",
    "assembler1 = VectorAssembler(inputCols=columns, outputCol=\"assembledColumns\")\n",
    "scaler = StandardScaler(inputCol=\"assembledColumns\", outputCol=\"standardColumns\", withStd=True, withMean=True)\n",
    "columns = ['t1_members', 't2_members', 'b_firstBlood', 'b_firstBaron', 'b_firstDragon', 'b_firstInhibitor', 'b_firstRiftHerald', 'b_firstTower', 'standardColumns']\n",
    "assembler2 = VectorAssembler(inputCols=columns, outputCol='features')\n",
    "pca = PCA(inputCol='features', outputCol='red_features')\n",
    "logistic = LogisticRegression(labelCol='winner_b',featuresCol='red_features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "params = ParamGridBuilder().addGrid(logistic.elasticNetParam, [0, 0.33]).\\\n",
    "    addGrid(pca.k, [50, 100]).addGrid(logistic.regParam, [0.1, 0.33]).addGrid(logistic.maxIter,[50]).build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import CrossValidator\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "from datetime import date, time, datetime\n",
    "evaluator = MulticlassClassificationEvaluator(metricName='accuracy', predictionCol='prediction', labelCol='winner_b')\n",
    "pipeline = Pipeline().setStages([cv1, cv2, binarizer, ohe, assembler1, scaler, assembler2, pca, logistic])\n",
    "cv = CrossValidator().setEstimator(pipeline).setEvaluator(evaluator).setEstimatorParamMaps(params).setNumFolds(3)\n",
    "model = cv.fit(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se importa el metodo now de la libreria datetime y se a√±ade al final de cada una de las iteraciones de la validacion cruzada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9610477779428821 50 0.1 0.0 2023-02-27 18:22:53.948474\n",
      "0.9598881584128409 50 0.33 0.0 2023-02-27 18:22:53.953825\n",
      "0.8112438715150688 100 0.1 0.0 2023-02-27 18:22:53.955276\n",
      "0.959392372568648 100 0.33 0.0 2023-02-27 18:22:53.955636\n",
      "0.8022294736513452 50 0.1 0.33 2023-02-27 18:22:53.956042\n",
      "0.7890024484969359 50 0.33 0.33 2023-02-27 18:22:53.956854\n",
      "0.8022294736513452 100 0.1 0.33 2023-02-27 18:22:53.959195\n",
      "0.7890024484969359 100 0.33 0.33 2023-02-27 18:22:53.959393\n",
      "tiempo medio transcurrido:\n",
      "0:00:00.001639\n",
      "La precision del modelo es:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9599658725470893"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inicio=datetime.now()\n",
    "for (result, config) in zip(model.avgMetrics, params) :\n",
    "    print(result, config[pca.k], config[logistic.regParam], config[logistic.elasticNetParam],datetime.now())\n",
    "fin=datetime.now()\n",
    "tiempo=fin-inicio\n",
    "print(\"tiempo medio transcurrido:\")\n",
    "print(tiempo/7)\n",
    "print(\"La precision del modelo es:\")\n",
    "evaluator.evaluate(model.transform(test_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejercicio 2. Se modifica elasticNetParam probando dos valores mas entre 0 y 1, regParam probando 3 valores mas entre 0 y 10 y maxlter probando 2 valores mas entre 1 y 100."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "elasticNetParam= 0.60, regParam=5 y maxIter=90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8103726793407865 50 0.1 0.0 2023-02-27 18:13:19.745998\n",
      "0.7765723489379416 50 5.0 0.0 2023-02-27 18:13:19.746160\n",
      "0.8101500165539968 100 0.1 0.0 2023-02-27 18:13:19.746571\n",
      "0.7781720812788453 100 5.0 0.0 2023-02-27 18:13:19.746646\n",
      "0.934033426935555 50 0.1 0.6 2023-02-27 18:13:19.746722\n",
      "0.5092822923265609 50 5.0 0.6 2023-02-27 18:13:19.746818\n",
      "0.7954121644770833 100 0.1 0.6 2023-02-27 18:13:19.762214\n",
      "0.5092822923265609 100 5.0 0.6 2023-02-27 18:13:19.762856\n",
      "tiempo medio transcurrido:\n",
      "0:00:00.002470\n",
      "La precision del modelo es:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9373325491733647"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "params = ParamGridBuilder().addGrid(logistic.elasticNetParam, [0, 0.60]).\\\n",
    "    addGrid(pca.k, [50, 100]).addGrid(logistic.regParam, [0.1, 5]).addGrid(logistic.maxIter,[90]).build()\n",
    "evaluator = MulticlassClassificationEvaluator(metricName='accuracy', predictionCol='prediction', labelCol='winner_b')\n",
    "pipeline = Pipeline().setStages([cv1, cv2, binarizer, ohe, assembler1, scaler, assembler2, pca, logistic])\n",
    "cv = CrossValidator().setEstimator(pipeline).setEvaluator(evaluator).setEstimatorParamMaps(params).setNumFolds(3)\n",
    "model = cv.fit(train_df)\n",
    "evaluator.evaluate(model.transform(test_df))\n",
    "from datetime import date, time, datetime\n",
    "inicio=datetime.now()\n",
    "for (result, config) in zip(model.avgMetrics, params) :\n",
    "    print(result, config[pca.k], config[logistic.regParam], config[logistic.elasticNetParam],datetime.now())\n",
    "fin=datetime.now()\n",
    "tiempo=fin-inicio\n",
    "print(\"tiempo medio transcurrido:\")\n",
    "print(tiempo/7)\n",
    "print(\"La precision del modelo es:\")\n",
    "evaluator.evaluate(model.transform(test_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "elasticNetParam= 0.20, regParam=2 y maxIter=25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9610477779428821 50 0.1 0.0 2023-02-27 18:26:20.752849\n",
      "0.8049951398950478 50 2.0 0.0 2023-02-27 18:26:20.753074\n",
      "0.8112438715150688 100 0.1 0.0 2023-02-27 18:26:20.771439\n",
      "0.8054914565537539 100 2.0 0.0 2023-02-27 18:26:20.771963\n",
      "0.8058662820554174 50 0.1 0.2 2023-02-27 18:26:20.772292\n",
      "0.5083270246274084 50 2.0 0.2 2023-02-27 18:26:20.772348\n",
      "0.952629150413907 100 0.1 0.2 2023-02-27 18:26:20.772702\n",
      "0.5083270246274084 100 2.0 0.2 2023-02-27 18:26:20.773336\n",
      "tiempo medio transcurrido:\n",
      "0:00:00.003005\n",
      "La precision del modelo es:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9599658725470893"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "params = ParamGridBuilder().addGrid(logistic.elasticNetParam, [0, 0.20]).\\\n",
    "    addGrid(pca.k, [50, 100]).addGrid(logistic.regParam, [0.1, 2]).addGrid(logistic.maxIter,[25]).build()\n",
    "evaluator = MulticlassClassificationEvaluator(metricName='accuracy', predictionCol='prediction', labelCol='winner_b')\n",
    "pipeline = Pipeline().setStages([cv1, cv2, binarizer, ohe, assembler1, scaler, assembler2, pca, logistic])\n",
    "cv = CrossValidator().setEstimator(pipeline).setEvaluator(evaluator).setEstimatorParamMaps(params).setNumFolds(3)\n",
    "model = cv.fit(train_df)\n",
    "evaluator.evaluate(model.transform(test_df))\n",
    "from datetime import date, time, datetime\n",
    "inicio=datetime.now()\n",
    "for (result, config) in zip(model.avgMetrics, params) :\n",
    "    print(result, config[pca.k], config[logistic.regParam], config[logistic.elasticNetParam],datetime.now())\n",
    "fin=datetime.now()\n",
    "tiempo=fin-inicio\n",
    "print(\"tiempo medio transcurrido:\")\n",
    "print(tiempo/7)\n",
    "print(\"La precision del modelo es:\")\n",
    "evaluator.evaluate(model.transform(test_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "elasticNetParam= 0.60, regParam=1 y maxIter=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8111887631808984 50 0.1 0.0 2023-02-27 18:28:24.306478\n",
      "0.8090410755785312 50 1.0 0.0 2023-02-27 18:28:24.306626\n",
      "0.9609093725423957 100 0.1 0.0 2023-02-27 18:28:24.306716\n",
      "0.8091780776988183 100 1.0 0.0 2023-02-27 18:28:24.306805\n",
      "0.7965797590325698 50 0.1 0.6 2023-02-27 18:28:24.306893\n",
      "0.5083270246274084 50 1.0 0.6 2023-02-27 18:28:24.316011\n",
      "0.7965797590325698 100 0.1 0.6 2023-02-27 18:28:24.317384\n",
      "0.5083270246274084 100 1.0 0.6 2023-02-27 18:28:24.317446\n",
      "tiempo medio transcurrido:\n",
      "0:00:00.001719\n",
      "La precision del modelo es:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9608846885869922"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "params = ParamGridBuilder().addGrid(logistic.elasticNetParam, [0, 0.60]).\\\n",
    "    addGrid(pca.k, [50, 100]).addGrid(logistic.regParam, [0.1, 1]).addGrid(logistic.maxIter,[10]).build()\n",
    "evaluator = MulticlassClassificationEvaluator(metricName='accuracy', predictionCol='prediction', labelCol='winner_b')\n",
    "pipeline = Pipeline().setStages([cv1, cv2, binarizer, ohe, assembler1, scaler, assembler2, pca, logistic])\n",
    "cv = CrossValidator().setEstimator(pipeline).setEvaluator(evaluator).setEstimatorParamMaps(params).setNumFolds(3)\n",
    "model = cv.fit(train_df)\n",
    "evaluator.evaluate(model.transform(test_df))\n",
    "from datetime import date, time, datetime\n",
    "inicio=datetime.now()\n",
    "for (result, config) in zip(model.avgMetrics, params) :\n",
    "    print(result, config[pca.k], config[logistic.regParam], config[logistic.elasticNetParam],datetime.now())\n",
    "fin=datetime.now()\n",
    "tiempo=fin-inicio\n",
    "print(\"tiempo medio transcurrido:\")\n",
    "print(tiempo/7)\n",
    "print(\"La precision del modelo es:\")\n",
    "evaluator.evaluate(model.transform(test_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejercicio3. Uso de Random Forest. Para ello se crea un pipeline cambiando el logistic por el random forest.Para ver con mayor claridad los cambios, se elige en el primer Random Forest un valor bajo, el el segundo uno medio y en el ultimo valores altos.\n",
    "Se ha probado con 2 arboles y con una profundidad de 2 en el primer caso, en el siguiente se prueba con 50 arboles y 5 de profundidad y en el ultimo con 100 arboles y 10 de profundidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "[train_df, test_df]=games_red_df.randomSplit([0.7, 0.3])\n",
    "train_df = train_df.withColumn('winner', train_df.winner.cast(DoubleType()))\n",
    "test_df = test_df.withColumn('winner', test_df.winner.cast(DoubleType()))\n",
    "new_column_expression = expr('split( concat_ws( \",\" ,t1_champ1id, t1_champ2id, t1_champ3id, t1_champ4id, t1_champ5id), \",\" )' )\n",
    "train_df = train_df.withColumn('t1_members_str',new_column_expression)\n",
    "test_df = test_df.withColumn('t1_members_str', new_column_expression)\n",
    "new_column_expression = expr('split( concat_ws( \",\" ,t2_champ1id, t2_champ2id, t2_champ3id, t2_champ4id, t2_champ5id), \",\" )' )\n",
    "train_df = train_df.withColumn('t2_members_str',new_column_expression)\n",
    "test_df = test_df.withColumn('t2_members_str', new_column_expression)\n",
    "cv1 = CountVectorizer(inputCol='t1_members_str', outputCol='t1_members')\n",
    "cv2 = CountVectorizer(inputCol='t2_members_str', outputCol='t2_members')\n",
    "binarizer=Binarizer(inputCol='winner', outputCol='winner_b', threshold=1)\n",
    "columns = ['firstBlood', 'firstTower', 'firstInhibitor', 'firstBaron', 'firstDragon', 'firstRiftHerald']\n",
    "new_columns = [ 'b_firstBlood', 'b_firstTower', 'b_firstInhibitor', 'b_firstBaron', 'b_firstDragon', 'b_firstRiftHerald' ]\n",
    "ohe = OneHotEncoderEstimator(inputCols=columns, outputCols=new_columns,dropLast=False)\n",
    "columns = [\"duration\", \"t1_towerKills\", \"t1_inhibitorKills\", \"t1_baronKills\", \"t1_dragonKills\", \"t1_riftHeraldKills\",\n",
    "          \"t2_towerKills\", \"t2_inhibitorKills\", \"t2_baronKills\", \"t2_dragonKills\", \"t2_riftHeraldKills\"]\n",
    "assembler1 = VectorAssembler(inputCols=columns, outputCol=\"assembledColumns\")\n",
    "scaler = StandardScaler(inputCol=\"assembledColumns\", outputCol=\"standardColumns\", withStd=True, withMean=True)\n",
    "columns = ['t1_members', 't2_members', 'b_firstBlood', 'b_firstBaron', 'b_firstDragon', 'b_firstInhibitor', 'b_firstRiftHerald', 'b_firstTower', 'standardColumns']\n",
    "assembler2 = VectorAssembler(inputCols=columns, outputCol='features')\n",
    "pca = PCA(inputCol='features', outputCol='red_features')\n",
    "randomF= RandomForestClassifier(labelCol='winner_b',featuresCol='red_features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "params = ParamGridBuilder().addGrid(pca.k, [50, 100]).addGrid(randomF.numTrees, [2]).addGrid(randomF.maxDepth,[2]).build()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8770691092968255 50 2 2 2023-02-27 18:29:39.344131\n",
      "0.6450244335667823 100 2 2 2023-02-27 18:29:39.344275\n",
      "tiempo medio transcurrido:\n",
      "0:00:00.000402\n",
      "La precision del modelo es:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9253867745936419"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.tuning import CrossValidator\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "evaluator = MulticlassClassificationEvaluator(metricName='accuracy', predictionCol='prediction', labelCol='winner_b')\n",
    "pipeline = Pipeline().setStages([cv1, cv2, binarizer, ohe, assembler1, scaler, assembler2, pca, randomF])\n",
    "cv = CrossValidator().setEstimator(pipeline).setEvaluator(evaluator).setEstimatorParamMaps(params).setNumFolds(3)\n",
    "model = cv.fit(train_df)\n",
    "evaluator.evaluate(model.transform(test_df))\n",
    "from datetime import date, time, datetime\n",
    "inicio=datetime.now()\n",
    "for (result, config) in zip(model.avgMetrics, params) :\n",
    "    print(result, config[pca.k], config[randomF.numTrees], config[randomF.maxDepth],datetime.now())\n",
    "fin=datetime.now()\n",
    "tiempo=fin-inicio\n",
    "print(\"tiempo medio transcurrido:\")\n",
    "print(tiempo)\n",
    "print(\"La precision del modelo es:\")\n",
    "evaluator.evaluate(model.transform(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9376017400762685 50 50 5 2023-02-27 18:31:22.017891\n",
      "0.9352532285144657 100 50 5 2023-02-27 18:31:22.018193\n",
      "tiempo medio transcurrido:\n",
      "0:00:00.000751\n",
      "La precision del modelo es:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9355702069325674"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "params = ParamGridBuilder().addGrid(pca.k, [50, 100]).addGrid(randomF.numTrees, [50]).addGrid(randomF.maxDepth,[5]).build()\n",
    "from pyspark.ml.tuning import CrossValidator\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "evaluator = MulticlassClassificationEvaluator(metricName='accuracy', predictionCol='prediction', labelCol='winner_b')\n",
    "pipeline = Pipeline().setStages([cv1, cv2, binarizer, ohe, assembler1, scaler, assembler2, pca, randomF])\n",
    "cv = CrossValidator().setEstimator(pipeline).setEvaluator(evaluator).setEstimatorParamMaps(params).setNumFolds(3)\n",
    "model = cv.fit(train_df)\n",
    "evaluator.evaluate(model.transform(test_df))\n",
    "from datetime import date, time, datetime\n",
    "inicio=datetime.now()\n",
    "for (result, config) in zip(model.avgMetrics, params) :\n",
    "    print(result, config[pca.k], config[randomF.numTrees], config[randomF.maxDepth],datetime.now())\n",
    "fin=datetime.now()\n",
    "tiempo=fin-inicio\n",
    "print(\"tiempo medio transcurrido:\")\n",
    "print(tiempo)\n",
    "print(\"La precision del modelo es:\")\n",
    "evaluator.evaluate(model.transform(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9534432133787154 50 100 10 2023-02-27 18:35:32.622993\n",
      "0.9477241081613559 100 100 10 2023-02-27 18:35:32.632938\n",
      "tiempo medio transcurrido:\n",
      "0:00:00.010861\n",
      "La precision del modelo es:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9552190090736993"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "params = ParamGridBuilder().addGrid(pca.k, [50, 100]).addGrid(randomF.numTrees, [100]).addGrid(randomF.maxDepth,[10]).build()\n",
    "from pyspark.ml.tuning import CrossValidator\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "evaluator = MulticlassClassificationEvaluator(metricName='accuracy', predictionCol='prediction', labelCol='winner_b')\n",
    "pipeline = Pipeline().setStages([cv1, cv2, binarizer, ohe, assembler1, scaler, assembler2, pca, randomF])\n",
    "cv = CrossValidator().setEstimator(pipeline).setEvaluator(evaluator).setEstimatorParamMaps(params).setNumFolds(3)\n",
    "model = cv.fit(train_df)\n",
    "evaluator.evaluate(model.transform(test_df))\n",
    "from datetime import date, time, datetime\n",
    "inicio=datetime.now()\n",
    "for (result, config) in zip(model.avgMetrics, params) :\n",
    "    print(result, config[pca.k], config[randomF.numTrees], config[randomF.maxDepth],datetime.now())\n",
    "fin=datetime.now()\n",
    "tiempo=fin-inicio\n",
    "print(\"tiempo medio transcurrido:\")\n",
    "print(tiempo)\n",
    "print(\"La precision del modelo es:\")\n",
    "evaluator.evaluate(model.transform(test_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejercicio4. Uso de Gradient Boosted Tree.En el primer caso se prueba con 10 maxIer y 6 maxDepth, sin reduccion de variables PCA.\n",
    "Luego se repite el proceso, reducciendo las variables PCA  se eliminan 'b_firstTower'y 'standardColumns\".En el segundo caso, se prueba con 20 maxIter y 12 de maxDepth.(probe con 90 y 10 y no terminaba..)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import GBTClassifier\n",
    "[train_df, test_df]=games_red_df.randomSplit([0.7, 0.3])\n",
    "train_df = train_df.withColumn('winner', train_df.winner.cast(DoubleType()))\n",
    "test_df = test_df.withColumn('winner', test_df.winner.cast(DoubleType()))\n",
    "new_column_expression = expr('split( concat_ws( \",\" ,t1_champ1id, t1_champ2id, t1_champ3id, t1_champ4id, t1_champ5id), \",\" )' )\n",
    "train_df = train_df.withColumn('t1_members_str',new_column_expression)\n",
    "test_df = test_df.withColumn('t1_members_str', new_column_expression)\n",
    "new_column_expression = expr('split( concat_ws( \",\" ,t2_champ1id, t2_champ2id, t2_champ3id, t2_champ4id, t2_champ5id), \",\" )' )\n",
    "train_df = train_df.withColumn('t2_members_str',new_column_expression)\n",
    "test_df = test_df.withColumn('t2_members_str', new_column_expression)\n",
    "cv1 = CountVectorizer(inputCol='t1_members_str', outputCol='t1_members')\n",
    "cv2 = CountVectorizer(inputCol='t2_members_str', outputCol='t2_members')\n",
    "binarizer=Binarizer(inputCol='winner', outputCol='winner_b', threshold=1)\n",
    "columns = ['firstBlood', 'firstTower', 'firstInhibitor', 'firstBaron', 'firstDragon', 'firstRiftHerald']\n",
    "new_columns = [ 'b_firstBlood', 'b_firstTower', 'b_firstInhibitor', 'b_firstBaron', 'b_firstDragon', 'b_firstRiftHerald' ]\n",
    "ohe = OneHotEncoderEstimator(inputCols=columns, outputCols=new_columns,dropLast=False)\n",
    "columns = [\"duration\", \"t1_towerKills\", \"t1_inhibitorKills\", \"t1_baronKills\", \"t1_dragonKills\", \"t1_riftHeraldKills\",\n",
    "          \"t2_towerKills\", \"t2_inhibitorKills\", \"t2_baronKills\", \"t2_dragonKills\", \"t2_riftHeraldKills\"]\n",
    "assembler1 = VectorAssembler(inputCols=columns, outputCol=\"assembledColumns\")\n",
    "scaler = StandardScaler(inputCol=\"assembledColumns\", outputCol=\"standardColumns\", withStd=True, withMean=True)\n",
    "columns = ['t1_members', 't2_members', 'b_firstBlood', 'b_firstBaron', 'b_firstDragon', 'b_firstInhibitor', 'b_firstRiftHerald', 'b_firstTower', 'standardColumns']\n",
    "assembler2 = VectorAssembler(inputCols=columns, outputCol='features')\n",
    "pca = PCA(inputCol='features', outputCol='red_features')\n",
    "GBT= GBTClassifier(labelCol='winner_b',featuresCol='red_features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "params = ParamGridBuilder().addGrid(pca.k, [50, 100]).addGrid(GBT.maxIter, [10]).addGrid(GBT.maxDepth,[6]).build()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9447292616955199 50 10 6 2023-02-27 18:46:46.000559\n",
      "0.9542787305589964 100 10 6 2023-02-27 18:46:46.000716\n",
      "tiempo medio transcurrido:\n",
      "0:00:00.000422\n",
      "La precision del modelo es:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9542219657626466"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.tuning import CrossValidator\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "evaluator = MulticlassClassificationEvaluator(metricName='accuracy', predictionCol='prediction', labelCol='winner_b')\n",
    "pipeline = Pipeline().setStages([cv1, cv2, binarizer, ohe, assembler1, scaler, assembler2, pca, GBT])\n",
    "cv = CrossValidator().setEstimator(pipeline).setEvaluator(evaluator).setEstimatorParamMaps(params).setNumFolds(3)\n",
    "model = cv.fit(train_df)\n",
    "evaluator.evaluate(model.transform(test_df))\n",
    "from datetime import date, time, datetime\n",
    "inicio=datetime.now()\n",
    "for (result, config) in zip(model.avgMetrics, params) :\n",
    "    print(result, config[pca.k], config[GBT.maxIter],config[GBT.maxDepth],datetime.now())\n",
    "fin=datetime.now()\n",
    "tiempo=fin-inicio\n",
    "print(\"tiempo medio transcurrido:\")\n",
    "print(tiempo)\n",
    "print(\"La precision del modelo es:\")\n",
    "evaluator.evaluate(model.transform(test_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se eliminan de PCA las variables 'b_firstTower', 'standardColumns'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8910948645136687 50 10 6 2023-02-27 18:51:46.010620\n",
      "0.8913742299618225 100 10 6 2023-02-27 18:51:46.010734\n",
      "tiempo medio transcurrido:\n",
      "0:00:00.000345\n",
      "La precision del modelo es:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8897647888226623"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.classification import GBTClassifier\n",
    "[train_df, test_df]=games_red_df.randomSplit([0.7, 0.3])\n",
    "train_df = train_df.withColumn('winner', train_df.winner.cast(DoubleType()))\n",
    "test_df = test_df.withColumn('winner', test_df.winner.cast(DoubleType()))\n",
    "new_column_expression = expr('split( concat_ws( \",\" ,t1_champ1id, t1_champ2id, t1_champ3id, t1_champ4id, t1_champ5id), \",\" )' )\n",
    "train_df = train_df.withColumn('t1_members_str',new_column_expression)\n",
    "test_df = test_df.withColumn('t1_members_str', new_column_expression)\n",
    "new_column_expression = expr('split( concat_ws( \",\" ,t2_champ1id, t2_champ2id, t2_champ3id, t2_champ4id, t2_champ5id), \",\" )' )\n",
    "train_df = train_df.withColumn('t2_members_str',new_column_expression)\n",
    "test_df = test_df.withColumn('t2_members_str', new_column_expression)\n",
    "cv1 = CountVectorizer(inputCol='t1_members_str', outputCol='t1_members')\n",
    "cv2 = CountVectorizer(inputCol='t2_members_str', outputCol='t2_members')\n",
    "binarizer=Binarizer(inputCol='winner', outputCol='winner_b', threshold=1)\n",
    "columns = ['firstBlood', 'firstTower', 'firstInhibitor', 'firstBaron', 'firstDragon', 'firstRiftHerald']\n",
    "new_columns = [ 'b_firstBlood', 'b_firstTower', 'b_firstInhibitor', 'b_firstBaron', 'b_firstDragon', 'b_firstRiftHerald' ]\n",
    "ohe = OneHotEncoderEstimator(inputCols=columns, outputCols=new_columns,dropLast=False)\n",
    "columns = [\"duration\", \"t1_towerKills\", \"t1_inhibitorKills\", \"t1_baronKills\", \"t1_dragonKills\", \"t1_riftHeraldKills\",\n",
    "          \"t2_towerKills\", \"t2_inhibitorKills\", \"t2_baronKills\", \"t2_dragonKills\", \"t2_riftHeraldKills\"]\n",
    "assembler1 = VectorAssembler(inputCols=columns, outputCol=\"assembledColumns\")\n",
    "scaler = StandardScaler(inputCol=\"assembledColumns\", outputCol=\"standardColumns\", withStd=True, withMean=True)\n",
    "columns = ['t1_members', 't2_members', 'b_firstBlood', 'b_firstBaron', 'b_firstDragon', 'b_firstInhibitor', 'b_firstRiftHerald']\n",
    "assembler2 = VectorAssembler(inputCols=columns, outputCol='features')\n",
    "pca = PCA(inputCol='features', outputCol='red_features')\n",
    "GBT= GBTClassifier(labelCol='winner_b',featuresCol='red_features')\n",
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "params = ParamGridBuilder().addGrid(pca.k, [50, 100]).addGrid(GBT.maxIter, [10]).addGrid(GBT.maxDepth,[6]).build()\n",
    "from pyspark.ml.tuning import CrossValidator\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "evaluator = MulticlassClassificationEvaluator(metricName='accuracy', predictionCol='prediction', labelCol='winner_b')\n",
    "pipeline = Pipeline().setStages([cv1, cv2, binarizer, ohe, assembler1, scaler, assembler2, pca, GBT])\n",
    "cv = CrossValidator().setEstimator(pipeline).setEvaluator(evaluator).setEstimatorParamMaps(params).setNumFolds(3)\n",
    "model = cv.fit(train_df)\n",
    "evaluator.evaluate(model.transform(test_df))\n",
    "from datetime import date, time, datetime\n",
    "inicio=datetime.now()\n",
    "for (result, config) in zip(model.avgMetrics, params) :\n",
    "    print(result, config[pca.k], config[GBT.maxIter],config[GBT.maxDepth],datetime.now())\n",
    "fin=datetime.now()\n",
    "tiempo=fin-inicio\n",
    "print(\"tiempo medio transcurrido:\")\n",
    "print(tiempo)\n",
    "print(\"La precision del modelo es:\")\n",
    "evaluator.evaluate(model.transform(test_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20 maxIter y 12 de maxDepth y con reduccion de PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8722374558296935 50 20 12 2023-02-27 19:49:58.107114\n",
      "0.8681433060151047 100 20 12 2023-02-27 19:49:58.107247\n",
      "tiempo medio transcurrido:\n",
      "0:00:00.001093\n",
      "La precision del modelo es:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8740731104462078"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.classification import GBTClassifier\n",
    "[train_df, test_df]=games_red_df.randomSplit([0.7, 0.3])\n",
    "train_df = train_df.withColumn('winner', train_df.winner.cast(DoubleType()))\n",
    "test_df = test_df.withColumn('winner', test_df.winner.cast(DoubleType()))\n",
    "new_column_expression = expr('split( concat_ws( \",\" ,t1_champ1id, t1_champ2id, t1_champ3id, t1_champ4id, t1_champ5id), \",\" )' )\n",
    "train_df = train_df.withColumn('t1_members_str',new_column_expression)\n",
    "test_df = test_df.withColumn('t1_members_str', new_column_expression)\n",
    "new_column_expression = expr('split( concat_ws( \",\" ,t2_champ1id, t2_champ2id, t2_champ3id, t2_champ4id, t2_champ5id), \",\" )' )\n",
    "train_df = train_df.withColumn('t2_members_str',new_column_expression)\n",
    "test_df = test_df.withColumn('t2_members_str', new_column_expression)\n",
    "cv1 = CountVectorizer(inputCol='t1_members_str', outputCol='t1_members')\n",
    "cv2 = CountVectorizer(inputCol='t2_members_str', outputCol='t2_members')\n",
    "binarizer=Binarizer(inputCol='winner', outputCol='winner_b', threshold=1)\n",
    "columns = ['firstBlood', 'firstTower', 'firstInhibitor', 'firstBaron', 'firstDragon', 'firstRiftHerald']\n",
    "new_columns = [ 'b_firstBlood', 'b_firstTower', 'b_firstInhibitor', 'b_firstBaron', 'b_firstDragon', 'b_firstRiftHerald' ]\n",
    "ohe = OneHotEncoderEstimator(inputCols=columns, outputCols=new_columns,dropLast=False)\n",
    "columns = [\"duration\", \"t1_towerKills\", \"t1_inhibitorKills\", \"t1_baronKills\", \"t1_dragonKills\", \"t1_riftHeraldKills\",\n",
    "          \"t2_towerKills\", \"t2_inhibitorKills\", \"t2_baronKills\", \"t2_dragonKills\", \"t2_riftHeraldKills\"]\n",
    "assembler1 = VectorAssembler(inputCols=columns, outputCol=\"assembledColumns\")\n",
    "scaler = StandardScaler(inputCol=\"assembledColumns\", outputCol=\"standardColumns\", withStd=True, withMean=True)\n",
    "columns = ['t1_members', 't2_members', 'b_firstBlood', 'b_firstBaron', 'b_firstDragon', 'b_firstInhibitor', 'b_firstRiftHerald']\n",
    "assembler2 = VectorAssembler(inputCols=columns, outputCol='features')\n",
    "pca = PCA(inputCol='features', outputCol='red_features')\n",
    "GBT= GBTClassifier(labelCol='winner_b',featuresCol='red_features')\n",
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "params = ParamGridBuilder().addGrid(pca.k, [50, 100]).addGrid(GBT.maxIter, [20]).addGrid(GBT.maxDepth,[12]).build()\n",
    "from pyspark.ml.tuning import CrossValidator\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "evaluator = MulticlassClassificationEvaluator(metricName='accuracy', predictionCol='prediction', labelCol='winner_b')\n",
    "pipeline = Pipeline().setStages([cv1, cv2, binarizer, ohe, assembler1, scaler, assembler2, pca, GBT])\n",
    "cv = CrossValidator().setEstimator(pipeline).setEvaluator(evaluator).setEstimatorParamMaps(params).setNumFolds(3)\n",
    "model = cv.fit(train_df)\n",
    "evaluator.evaluate(model.transform(test_df))\n",
    "from datetime import date, time, datetime\n",
    "inicio=datetime.now()\n",
    "for (result, config) in zip(model.avgMetrics, params) :\n",
    "    print(result, config[pca.k], config[GBT.maxIter],config[GBT.maxDepth],datetime.now())\n",
    "fin=datetime.now()\n",
    "tiempo=fin-inicio\n",
    "print(\"tiempo medio transcurrido:\")\n",
    "print(tiempo)\n",
    "print(\"La precision del modelo es:\")\n",
    "evaluator.evaluate(model.transform(test_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el calculo del tiempo se usa datetime.now al principio de bucle for y cuando termina dicho bucle. Esto a√±ade algo mas de tiempo que el tiempo real pero como se calcula en todos los procesos por igual, el valor a√±adido es el mismo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistica\n",
    "elasticNetParam= 0.60, regParam=5 y maxIter=90\n",
    "tiempo medio transcurrido:\n",
    "0:00:00.002470\n",
    "La precision del modelo es:\n",
    "0.9373325491733647\n",
    "\n",
    "elasticNetParam= 0.20, regParam=2 y maxIter=25\n",
    "tiempo medio transcurrido:\n",
    "0:00:00.003005\n",
    "La precision del modelo es:\n",
    "0.9599658725470893\n",
    "\n",
    "elasticNetParam= 0.60, regParam=1 y maxIter=10--\n",
    "tiempo medio transcurrido:\n",
    "0:00:00.001719\n",
    "La precision del modelo es:\n",
    "0.9608846885869922\n",
    "\n",
    "Random Forest\n",
    "numTress=2 y maxDepth=2\n",
    "tiempo medio transcurrido:\n",
    "0:00:00.000402\n",
    "La precision del modelo es:\n",
    "0.9253867745936419\n",
    "\n",
    "numTress=50y maxDepth=5\n",
    "tiempo medio transcurrido:\n",
    "0:00:00.000751\n",
    "La precision del modelo es:\n",
    "0.9355702069325674\n",
    "\n",
    "numTress=100 maxDepth=10\n",
    "tiempo medio transcurrido:\n",
    "0:00:00.010861\n",
    "La precision del modelo es:\n",
    "0.9552190090736993\n",
    "\n",
    "\n",
    "Gradient Boosted Tree\n",
    "10 maxIer y 2 maxDepth sin reduccion--\n",
    "tiempo medio transcurrido:\n",
    "0:00:00.000422\n",
    "La precision del modelo es:\n",
    "0.9542219657626466\n",
    "\n",
    "10 maxIer y 2 maxDepth con reduccion--\n",
    "tiempo medio transcurrido:\n",
    "0:00:00.000345\n",
    "La precision del modelo es:\n",
    "0.8897647888226623\n",
    "\n",
    "20 maxIer y 12maxDepth con reduccion--\n",
    "tiempo medio transcurrido:\n",
    "0:00:00.001093\n",
    "La precision del modelo es:\n",
    "0.8740731104462078\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusiones:\n",
    "La cinfiguracion mas existosa ha sido la logistica con los siguientes parametros elasticNetParam= 0.60, regParam=1 y maxIter=10, alcanzando una precision de 96%.\n",
    "La que mas ha tardado ha sido el Random Forest con numTress=100 maxDepth=10 dandonos una precision de 95,5%.\n",
    "Si se eliminan variables en la PCA puede ocurrir dos casos:\n",
    "1- que esas variables no tengan mucha correlacion con nuestra variable objetivo y apenas influya en la precision.\n",
    "2- que tengan mas peso y que nos influya\n",
    "En el Gradient Boosted Tree se ejecuto la misma configuracion, 10 maxIter y 2 maxDepth, uno con todas las variables y en el otro eliminando 2 variables.\n",
    "En este caso nos ha bajado de un 95,4% a 88,97% la precision si bien el tiempo se ha reducido,no merece la pena ya que el porcentaje ha bajado demasiado, quizas con una reduccion de tiempo mayor cabria la oportunidad de pensarlo.\n",
    "Cabe destacar que una cosa es el tiempo de entrenamiento entre rondas, y otro es el tiempo de entrenar el modelo desde que se inicia, siendo los tiempos de entrenamiento cuando la profundidad y numero de arboles es muy alto muy superior al resto."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
