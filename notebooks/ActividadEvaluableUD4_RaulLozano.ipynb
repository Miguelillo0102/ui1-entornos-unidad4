{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import expr\n",
    "from pyspark.ml.feature import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.tuning import *\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import *\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leemos el csv y nos quedamos con las columnas que nos interesan. Además, hacemos las transformaciones de tipos necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "games_df = spark.read.csv('../data/games.csv', header=True, sep=',')\n",
    "\n",
    "games_red_df = games_df.selectExpr('winner', 'gameDuration as duration', 'firstBlood',\n",
    "                                   'firstTower', 'firstInhibitor', 'firstBaron',\n",
    "                                   'firstDragon', 'firstRiftHerald', 't1_champ1id',\n",
    "                                   't1_champ2id', 't1_champ3id', 't1_champ4id',\n",
    "                                   't1_champ5id','t1_towerKills', 't1_inhibitorKills',\n",
    "                                   't1_baronKills', 't1_dragonKills',\n",
    "                                   't1_riftHeraldKills',\n",
    "                                   't2_champ1id', 't2_champ2id', 't2_champ3id',\n",
    "                                   't2_champ4id', 't2_champ5id', 't2_towerKills',\n",
    "                                   't2_inhibitorKills', 't2_baronKills',\n",
    "                                   't2_dragonKills', 't2_riftHeraldKills')\n",
    "\n",
    "games_red_df = games_red_df.withColumn('firstBlood', games_red_df.firstBlood.cast(IntegerType()))\n",
    "games_red_df = games_red_df.withColumn('firstTower', games_red_df.firstTower.cast(IntegerType()))\n",
    "games_red_df = games_red_df.withColumn('firstInhibitor', games_red_df.firstInhibitor.cast(IntegerType()))\n",
    "games_red_df = games_red_df.withColumn('firstBaron', games_red_df.firstBaron.cast(IntegerType()))\n",
    "games_red_df = games_red_df.withColumn('firstDragon', games_red_df.firstDragon.cast(IntegerType()))\n",
    "games_red_df = games_red_df.withColumn('firstRiftHerald', games_red_df.firstRiftHerald.cast(IntegerType()))\n",
    "games_red_df = games_red_df.withColumn('t1_towerKills', games_red_df.t1_towerKills.cast(IntegerType()))\n",
    "games_red_df = games_red_df.withColumn('t1_inhibitorKills', games_red_df.t1_inhibitorKills.cast(IntegerType()))\n",
    "games_red_df = games_red_df.withColumn('t1_baronKills', games_red_df.t1_baronKills.cast(IntegerType()))\n",
    "games_red_df = games_red_df.withColumn('t1_dragonKills', games_red_df.t1_dragonKills.cast(IntegerType()))\n",
    "games_red_df = games_red_df.withColumn('t1_riftHeraldKills', games_red_df.t1_riftHeraldKills.cast(IntegerType()))\n",
    "games_red_df = games_red_df.withColumn('t2_towerKills', games_red_df.t2_towerKills.cast(IntegerType()))\n",
    "games_red_df = games_red_df.withColumn('t2_inhibitorKills', games_red_df.t2_inhibitorKills.cast(IntegerType()))\n",
    "games_red_df = games_red_df.withColumn('t2_baronKills', games_red_df.t2_baronKills.cast(IntegerType()))\n",
    "games_red_df = games_red_df.withColumn('t2_dragonKills', games_red_df.t2_dragonKills.cast(IntegerType()))\n",
    "games_red_df = games_red_df.withColumn('t2_riftHeraldKills', games_red_df.t2_riftHeraldKills.cast(IntegerType()))\n",
    "games_red_df = games_red_df.withColumn('duration', games_red_df.duration.cast(IntegerType()))\n",
    "games_red_df = games_red_df.withColumn('winner', games_red_df.winner.cast(DoubleType()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separamos el dataframe en dos: uno de entrenamiento y uno de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "[train_df, test_df] = games_red_df.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agrupamos los personajes de cada equipo en un array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_column_expression = expr('split( concat_ws( \",\" ,t1_champ1id, t1_champ2id, t1_champ3id, t1_champ4id, t1_champ5id), \",\" )' )\n",
    "train_df = train_df.withColumn('t1_members_str',new_column_expression)\n",
    "test_df = test_df.withColumn('t1_members_str', new_column_expression)\n",
    "new_column_expression = expr('split( concat_ws( \",\" ,t2_champ1id, t2_champ2id, t2_champ3id, t2_champ4id, t2_champ5id), \",\" )' )\n",
    "train_df = train_df.withColumn('t2_members_str',new_column_expression)\n",
    "test_df = test_df.withColumn('t2_members_str', new_column_expression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contamos el número de veces que aparecen los personajes usados en cada equipo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv1 = CountVectorizer(inputCol='t1_members_str', outputCol='t1_members')\n",
    "cv2 = CountVectorizer(inputCol='t2_members_str', outputCol='t2_members')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacemos que la variable winner sea binaria: 0 si gana el equipo 1, y 1 si gana el equipo 2. Esto lo hacemos a través de un Binarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "binarizer = Binarizer(inputCol='winner', outputCol='winner_b', threshold=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agrupamos varias columnas y las transformamos en variables binarias para no tratarlas como variables categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['firstBlood', 'firstTower', 'firstInhibitor', 'firstBaron', 'firstDragon', 'firstRiftHerald']\n",
    "new_columns = ['b_firstBlood', 'b_firstTower', 'b_firstInhibitor', 'b_firstBaron', 'b_firstDragon', 'b_firstRiftHerald' ]\n",
    "ohe = OneHotEncoderEstimator(inputCols=columns, outputCols=new_columns,dropLast=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unimos varias columnas con VectorAssembler y las escalamos con StandardScaler restándole la media a los valores y dividiéndolos por su desviación típica para trabajar con valores en la misma magnitud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"duration\", \"t1_towerKills\", \"t1_inhibitorKills\", \"t1_baronKills\", \"t1_dragonKills\", \"t1_riftHeraldKills\",\n",
    "          \"t2_towerKills\", \"t2_inhibitorKills\", \"t2_baronKills\", \"t2_dragonKills\", \"t2_riftHeraldKills\"]\n",
    "assembler1 = VectorAssembler(inputCols=columns, outputCol=\"assembledColumns\")\n",
    "scaler = StandardScaler(inputCol=\"assembledColumns\", outputCol=\"standardColumns\", withStd=True, withMean=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unimos varias columnas con vector assembler para utilizarlas para el PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['t1_members', 't2_members', 'b_firstBlood', 'b_firstBaron', 'b_firstDragon', 'b_firstInhibitor', 'b_firstRiftHerald', 'b_firstTower', 'standardColumns']\n",
    "assembler2 = VectorAssembler(inputCols=columns, outputCol='features')\n",
    "pca = PCA(inputCol='features', outputCol='red_features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejercicio 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105.021157\n",
      "------------------------------------------------------------------------------------------------\n",
      "0.9600710814343387 0.0 50 0.1 50\n",
      "0.9598457208408941 0.0 50 0.33 50\n",
      "0.960315063044797 0.0 100 0.1 50\n",
      "0.9595941274250777 0.0 100 0.33 50\n",
      "0.9478012318997993 0.33 50 0.1 50\n",
      "0.9274605728346121 0.33 50 0.33 50\n",
      "0.9478012318997993 0.33 100 0.1 50\n",
      "0.9274605728346121 0.33 100 0.33 50\n",
      "------------------------------------------------------------------------------------------------\n",
      "0.9610051428943428\n"
     ]
    }
   ],
   "source": [
    "logistic = LogisticRegression(labelCol='winner_b',featuresCol='red_features')\n",
    "evaluator = MulticlassClassificationEvaluator(metricName='accuracy', predictionCol='prediction', labelCol='winner_b')\n",
    "pipeline = Pipeline().setStages([cv1, cv2, binarizer, ohe, assembler1, scaler, assembler2, pca, logistic])\n",
    "\n",
    "params = ParamGridBuilder().addGrid(logistic.elasticNetParam, [0, 0.33]).\\\n",
    "    addGrid(pca.k, [50, 100]).addGrid(logistic.regParam, [0.1, 0.33]).addGrid(logistic.maxIter,[50]).build()\n",
    "\n",
    "fromDate = datetime.now()\n",
    "\n",
    "model = CrossValidator().setEstimator(pipeline).setEvaluator(evaluator).setEstimatorParamMaps(params).\\\n",
    "    setNumFolds(5).fit(train_df)\n",
    "\n",
    "print((datetime.now() - fromDate).total_seconds())\n",
    "\n",
    "print(\"------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "for (result, config) in zip(model.avgMetrics, params) :\n",
    "    print(result, config[logistic.elasticNetParam], config[pca.k], config[logistic.regParam], config[logistic.maxIter])\n",
    "\n",
    "print(\"------------------------------------------------------------------------------------------------\")\n",
    "    \n",
    "print(evaluator.evaluate(model.transform(test_df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejercicio 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1133.995956\n",
      "------------------------------------------------------------------------------------------------\n",
      "0.9600710814343387 0.0 50 0.1 50\n",
      "0.9600710814343387 0.0 50 0.1 10\n",
      "0.9600710814343387 0.0 50 0.1 90\n",
      "0.9598457208408941 0.0 50 0.33 50\n",
      "0.9598457208408941 0.0 50 0.33 10\n",
      "0.9598457208408941 0.0 50 0.33 90\n",
      "0.9585443486810321 0.0 50 1.0 50\n",
      "0.9585443486810321 0.0 50 1.0 10\n",
      "0.9585443486810321 0.0 50 1.0 90\n",
      "0.9327472088085138 0.0 50 5.0 50\n",
      "0.9327472088085138 0.0 50 5.0 10\n",
      "0.9327472088085138 0.0 50 5.0 90\n",
      "0.9081000232112197 0.0 50 7.0 50\n",
      "0.9081000232112197 0.0 50 7.0 10\n",
      "0.9081000232112197 0.0 50 7.0 90\n",
      "0.960315063044797 0.0 100 0.1 50\n",
      "0.960288147510727 0.0 100 0.1 10\n",
      "0.960315063044797 0.0 100 0.1 90\n",
      "0.9595941274250777 0.0 100 0.33 50\n",
      "0.9595941274250777 0.0 100 0.33 10\n",
      "0.9595941274250777 0.0 100 0.33 90\n",
      "0.958205713181232 0.0 100 1.0 50\n",
      "0.958205713181232 0.0 100 1.0 10\n",
      "0.958205713181232 0.0 100 1.0 90\n",
      "0.9347965509684086 0.0 100 5.0 50\n",
      "0.9347965509684086 0.0 100 5.0 10\n",
      "0.9347965509684086 0.0 100 5.0 90\n",
      "0.9111674481245282 0.0 100 7.0 50\n",
      "0.9111674481245282 0.0 100 7.0 10\n",
      "0.9111674481245282 0.0 100 7.0 90\n",
      "0.9478012318997993 0.33 50 0.1 50\n",
      "0.9478012318997993 0.33 50 0.1 10\n",
      "0.9478012318997993 0.33 50 0.1 90\n",
      "0.9274605728346121 0.33 50 0.33 50\n",
      "0.9274605728346121 0.33 50 0.33 10\n",
      "0.9274605728346121 0.33 50 0.33 90\n",
      "0.9056912596545059 0.33 50 1.0 50\n",
      "0.9056912596545059 0.33 50 1.0 10\n",
      "0.9056912596545059 0.33 50 1.0 90\n",
      "0.5069925914729806 0.33 50 5.0 50\n",
      "0.5069925914729806 0.33 50 5.0 10\n",
      "0.5069925914729806 0.33 50 5.0 90\n",
      "0.5069925914729806 0.33 50 7.0 50\n",
      "0.5069925914729806 0.33 50 7.0 10\n",
      "0.5069925914729806 0.33 50 7.0 90\n",
      "0.9478012318997993 0.33 100 0.1 50\n",
      "0.9478012318997993 0.33 100 0.1 10\n",
      "0.9478012318997993 0.33 100 0.1 90\n",
      "0.9274605728346121 0.33 100 0.33 50\n",
      "0.9274605728346121 0.33 100 0.33 10\n",
      "0.9274605728346121 0.33 100 0.33 90\n",
      "0.9056912596545059 0.33 100 1.0 50\n",
      "0.9056912596545059 0.33 100 1.0 10\n",
      "0.9056912596545059 0.33 100 1.0 90\n",
      "0.5069925914729806 0.33 100 5.0 50\n",
      "0.5069925914729806 0.33 100 5.0 10\n",
      "0.5069925914729806 0.33 100 5.0 90\n",
      "0.5069925914729806 0.33 100 7.0 50\n",
      "0.5069925914729806 0.33 100 7.0 10\n",
      "0.5069925914729806 0.33 100 7.0 90\n",
      "0.9421806170560776 0.5 50 0.1 50\n",
      "0.9421806170560776 0.5 50 0.1 10\n",
      "0.9421806170560776 0.5 50 0.1 90\n",
      "0.9272948557408381 0.5 50 0.33 50\n",
      "0.9272948557408381 0.5 50 0.33 10\n",
      "0.9272948557408381 0.5 50 0.33 90\n",
      "0.5069925914729806 0.5 50 1.0 50\n",
      "0.5069925914729806 0.5 50 1.0 10\n",
      "0.5069925914729806 0.5 50 1.0 90\n",
      "0.5069925914729806 0.5 50 5.0 50\n",
      "0.5069925914729806 0.5 50 5.0 10\n",
      "0.5069925914729806 0.5 50 5.0 90\n",
      "0.5069925914729806 0.5 50 7.0 50\n",
      "0.5069925914729806 0.5 50 7.0 10\n",
      "0.5069925914729806 0.5 50 7.0 90\n",
      "0.9421806170560776 0.5 100 0.1 50\n",
      "0.9421806170560776 0.5 100 0.1 10\n",
      "0.9421806170560776 0.5 100 0.1 90\n",
      "0.9272948557408381 0.5 100 0.33 50\n",
      "0.9272948557408381 0.5 100 0.33 10\n",
      "0.9272948557408381 0.5 100 0.33 90\n",
      "0.5069925914729806 0.5 100 1.0 50\n",
      "0.5069925914729806 0.5 100 1.0 10\n",
      "0.5069925914729806 0.5 100 1.0 90\n",
      "0.5069925914729806 0.5 100 5.0 50\n",
      "0.5069925914729806 0.5 100 5.0 10\n",
      "0.5069925914729806 0.5 100 5.0 90\n",
      "0.5069925914729806 0.5 100 7.0 50\n",
      "0.5069925914729806 0.5 100 7.0 10\n",
      "0.5069925914729806 0.5 100 7.0 90\n",
      "0.9364531172191626 0.66 50 0.1 50\n",
      "0.9364531172191626 0.66 50 0.1 10\n",
      "0.9364531172191626 0.66 50 0.1 90\n",
      "0.9271555247107527 0.66 50 0.33 50\n",
      "0.9271555247107527 0.66 50 0.33 10\n",
      "0.9271555247107527 0.66 50 0.33 90\n",
      "0.5069925914729806 0.66 50 1.0 50\n",
      "0.5069925914729806 0.66 50 1.0 10\n",
      "0.5069925914729806 0.66 50 1.0 90\n",
      "0.5069925914729806 0.66 50 5.0 50\n",
      "0.5069925914729806 0.66 50 5.0 10\n",
      "0.5069925914729806 0.66 50 5.0 90\n",
      "0.5069925914729806 0.66 50 7.0 50\n",
      "0.5069925914729806 0.66 50 7.0 10\n",
      "0.5069925914729806 0.66 50 7.0 90\n",
      "0.9364531172191626 0.66 100 0.1 50\n",
      "0.9364531172191626 0.66 100 0.1 10\n",
      "0.9364531172191626 0.66 100 0.1 90\n",
      "0.9271555247107527 0.66 100 0.33 50\n",
      "0.9271555247107527 0.66 100 0.33 10\n",
      "0.9271555247107527 0.66 100 0.33 90\n",
      "0.5069925914729806 0.66 100 1.0 50\n",
      "0.5069925914729806 0.66 100 1.0 10\n",
      "0.5069925914729806 0.66 100 1.0 90\n",
      "0.5069925914729806 0.66 100 5.0 50\n",
      "0.5069925914729806 0.66 100 5.0 10\n",
      "0.5069925914729806 0.66 100 5.0 90\n",
      "0.5069925914729806 0.66 100 7.0 50\n",
      "0.5069925914729806 0.66 100 7.0 10\n",
      "0.5069925914729806 0.66 100 7.0 90\n",
      "------------------------------------------------------------------------------------------------\n",
      "0.9610051428943428\n"
     ]
    }
   ],
   "source": [
    "logistic = LogisticRegression(labelCol='winner_b',featuresCol='red_features')\n",
    "evaluator = MulticlassClassificationEvaluator(metricName='accuracy', predictionCol='prediction', labelCol='winner_b')\n",
    "pipeline = Pipeline().setStages([cv1, cv2, binarizer, ohe, assembler1, scaler, assembler2, pca, logistic])\n",
    "\n",
    "params = ParamGridBuilder().addGrid(logistic.elasticNetParam, [0, 0.33, 0.5, 0.66]).\\\n",
    "    addGrid(pca.k, [50, 100]).addGrid(logistic.regParam, [0.1, 0.33, 1, 5, 7]).addGrid(logistic.maxIter,[50, 10, 90]).build()\n",
    "\n",
    "fromDate = datetime.now()\n",
    "\n",
    "model = CrossValidator().setEstimator(pipeline).setEvaluator(evaluator).setEstimatorParamMaps(params).\\\n",
    "    setNumFolds(5).fit(train_df)\n",
    "\n",
    "print((datetime.now() - fromDate).total_seconds())\n",
    "\n",
    "print(\"------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "for (result, config) in zip(model.avgMetrics, params) :\n",
    "    print(result, config[logistic.elasticNetParam], config[pca.k], config[logistic.regParam], config[logistic.maxIter])\n",
    "    \n",
    "print(\"------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "print(evaluator.evaluate(model.transform(test_df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejercicio 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "397.445755\n",
      "------------------------------------------------------------------------------------------------\n",
      "0.930166502837336 50 25 2\n",
      "0.9379770833152193 50 25 5\n",
      "0.943977836487595 50 25 7\n",
      "0.9304408465326807 50 50 2\n",
      "0.9379218780408931 50 50 5\n",
      "0.9438189825703925 50 50 7\n",
      "0.9311901454763646 50 75 2\n",
      "0.9363632139734741 50 75 5\n",
      "0.9437593630817676 50 75 7\n",
      "0.931577214062606 100 25 2\n",
      "0.9367884567970133 100 25 5\n",
      "0.9414636073240044 100 25 7\n",
      "0.933077010244555 100 50 2\n",
      "0.936096557046909 100 50 5\n",
      "0.9405178125824019 100 50 7\n",
      "0.9329109503872683 100 75 2\n",
      "0.9362279919034004 100 75 5\n",
      "0.9416572581722863 100 75 7\n",
      "------------------------------------------------------------------------------------------------\n",
      "0.9440791615129224\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(labelCol='winner_b', featuresCol='red_features')\n",
    "evaluator = MulticlassClassificationEvaluator(metricName='accuracy', predictionCol='prediction', labelCol='winner_b')\n",
    "pipeline = Pipeline().setStages([cv1, cv2, binarizer, ohe, assembler1, scaler, assembler2, pca, rf])\n",
    "\n",
    "params = ParamGridBuilder().addGrid(pca.k, [50, 100]).addGrid(rf.numTrees, [25, 50, 75]).\\\n",
    "    addGrid(rf.maxDepth, [2, 5, 7]).build()\n",
    "\n",
    "fromDate = datetime.now()\n",
    "\n",
    "model = CrossValidator().setEstimator(pipeline).setEvaluator(evaluator).setEstimatorParamMaps(params).\\\n",
    "    setNumFolds(5).fit(train_df)\n",
    "\n",
    "print((datetime.now() - fromDate).total_seconds())\n",
    "\n",
    "print(\"------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "for (result, config) in zip(model.avgMetrics, params) :\n",
    "    print(result, config[pca.k], config[rf.numTrees], config[rf.maxDepth])\n",
    "    \n",
    "print(\"------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "print(evaluator.evaluate(model.transform(test_df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejercicio 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "931.855396\n",
      "------------------------------------------------------------------------------------------------\n",
      "0.963057771519281 20 3\n",
      "0.9686979292718068 20 7\n",
      "0.9689484576003737 80 3\n",
      "0.9690834125559534 80 7\n",
      "------------------------------------------------------------------------------------------------\n",
      "0.9686869344443721\n"
     ]
    }
   ],
   "source": [
    "gbt = GBTClassifier(labelCol='winner_b',featuresCol='features')\n",
    "evaluator = MulticlassClassificationEvaluator(metricName='accuracy', predictionCol='prediction', labelCol='winner_b')\n",
    "pipeline = Pipeline().setStages([cv1, cv2, binarizer, ohe, assembler1, scaler, assembler2, gbt])\n",
    "\n",
    "params = ParamGridBuilder().addGrid(gbt.maxIter,[20, 80]).addGrid(gbt.maxDepth,[3, 7]).build()\n",
    "\n",
    "fromDate = datetime.now()\n",
    "\n",
    "model = CrossValidator().setEstimator(pipeline).setEvaluator(evaluator).setEstimatorParamMaps(params).\\\n",
    "    setNumFolds(5).fit(train_df)\n",
    "\n",
    "print((datetime.now() - fromDate).total_seconds())\n",
    "\n",
    "print(\"------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "for (result, config) in zip(model.avgMetrics, params) :\n",
    "    print(result, config[gbt.maxIter], config[gbt.maxDepth])\n",
    "    \n",
    "print(\"------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "print(evaluator.evaluate(model.transform(test_df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejercicio 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que, por lo general, los resultados del modelo Gradient-boosted tree son muy buenos. No obstante, con otros modelos también se han obtenido resultados muy buenos. Tenemos que, de media, el entrenamiento por modelo dura aproximadamente:\n",
    "- Regresión logística: 9.7 segundos\n",
    "- Random Forest: 22.08 segundos\n",
    "- Gradient-boosted tree: 3.88 minutos\n",
    "\n",
    "Vemos que utilizar un modelo Gradient-boosted tree es muy costoso, aunque dentro de lo que cabe es asumible. Si queremos una opción menos costosa en cuanto a tiempo, quizás no tan precisa pero mucho más rápida, podríamos usar una regresión logística. con una configuración en la que se utilice elasticNetParam = 0, PCA = 100, regParam = 0.1, y unas iteraciones que oscilen entre 50 y 90. Teniendo en cuenta esta información, intentamos obtener el modelo con más precisión:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.042631\n",
      "------------------------------------------------------------------------------------------------\n",
      "0.9626194609952959 0.0 75 0.006 10\n",
      "------------------------------------------------------------------------------------------------\n",
      "0.9618514419634139\n"
     ]
    }
   ],
   "source": [
    "logistic = LogisticRegression(labelCol='winner_b',featuresCol='red_features')\n",
    "evaluator = MulticlassClassificationEvaluator(metricName='accuracy', predictionCol='prediction', labelCol='winner_b')\n",
    "pipeline = Pipeline().setStages([cv1, cv2, binarizer, ohe, assembler1, scaler, assembler2, pca, logistic])\n",
    "\n",
    "params = ParamGridBuilder().addGrid(logistic.elasticNetParam,[0]).\\\n",
    "    addGrid(pca.k,[75]).addGrid(logistic.regParam,[0.006]).addGrid(logistic.maxIter,[10]).build()\n",
    "\n",
    "fromDate = datetime.now()\n",
    "\n",
    "model = CrossValidator().setEstimator(pipeline).setEvaluator(evaluator).setEstimatorParamMaps(params).\\\n",
    "    setNumFolds(5).fit(train_df)\n",
    "\n",
    "print((datetime.now() - fromDate).total_seconds())\n",
    "\n",
    "print(\"------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "for (result, config) in zip(model.avgMetrics, params) :\n",
    "    print(result, config[logistic.elasticNetParam], config[pca.k], config[logistic.regParam], config[logistic.maxIter])\n",
    "    \n",
    "print(\"------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "print(evaluator.evaluate(model.transform(test_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.9624818573602166 0.0 75 0.008 25\n",
    "0.9624818573602166 0.0 75 0.008 40\n",
    "0.9624818573602166 0.0 75 0.008 55\n",
    "\n",
    "0.9620467417485841"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
